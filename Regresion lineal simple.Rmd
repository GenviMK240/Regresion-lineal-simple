---
title: "Regresión lineal simple"
author: "Genoveva Serrano Fernández"
date: "2024-03-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##1.Si pretendiésemos explicar un suceso y/o fenómeno acontecido en el pasado ¿Podemos inferir la respuesta asociada a dichos eventos en base a los restos materiales presentes?
Podemos inferir esa respuesta ya que para que se pueda llevar a cabo estadística inferencial es necesario partir de una serie de datos empíricos, los cuales siempre vamos a tener en nuestros yacimientos en forma de restos arqueológicos, la cuestión es que esta estadística, mas bien su margen de error o inexactitud, está en la cantidad que poseamos de esos restos materiales. Siempre será necesario un muestreo y un mínimo de muestras para inferir la respuesta de un hecho en concreto, pero poder, se puede.

##2.Haciendo referencia al análisis de correlación lineal de Pearson, ¿establece este algún tipo de relación causa-efecto de una variable sobre otra(s)?
Este análisis no establece una relación de causa y efecto entre dos variables, solo mide el cómo cambian conjuntamente estas, si en la misma dirección o no, y si es en la misma proporción, pero no nos da el porqué ocurre esto.

##3.Define causalidad. Exponga algún ejemplo.
La causalidad indica una relación directa de casua y efecto entre dos eventos diferentes, es decir, que un evento es el resultado de otro evento, lo que los relaciona estrechamente.

Un ejemplo, una persona que sigue una dieta rigurosa y hace ejercicio, tendrá mejor salud.

##4.¿Podrías mencionar los parámetros involucrados en la ecuación de regresión lineal?
Principalmente son dos:
-El intercepto
-La pendiente

##5.En un plano cartesiano, si afirmo que el eje ‘x’ también se denomina eje de ordenadas, ¿estoy en lo cierto?
El eje "x" es el llamado "eje de abcisas", el "eje de ordenadas" es el eje "y" de un plano cartesiano.

##6.¿Sabrías diferenciar entre recta de regresión y plano de regresión?
La diferencia entre ambas radica entre que la recta de regresión se utiliza cuando solo hay una variable independiente, mientras que un plano de regresión se utiliza cuando hay dos o más variables independientes.

##7.¿Cuáles son los supuestos (o hipótesis) del análisis de regresión lineal?
Son cuatro:
-La linealidad
-La homocedasticidas
-La normalidad
-La independencia

##8.Dados los siguientes datos, calcula la recta de regresión que mejor se adapte a nuestra nube de puntos siendo “cuentas” la variable dependiente o de respuesta y “distancia” la variable independiente o explicativa.
Figura 1: Tabla de datos referidos a número de cuentas por yacimiento y distancia (km) del yacimiento a la mina. Fuente: Elaboración propia.
##9.¿Serías capaz de interpretar el significado de los parámetros de la ecuación de regresión?
La ecuación de la regresión es la siguiente: Y=b0 + b1X, siendo:
-b0, el intercepto: es el valor esperado de la variable dependiente (Y) cuando la variable independiente (X) es igual a cero.
Por ejemplo: si tenemos en la ecuación Y= 10 + 0.5X, siendo Y la temperatura respecto a la cantidad de horas de sol (X), en este caso, nuestra b0 sería 10 e indica que cuando existen 0 horas de sol, la temperatura es de 10ºC.

-b1, es la pendiente: indica indica cómo cambia la variable dependiente (Y) a medida que cambia la variable independiente (X).

Siguiendo el ejemplo anterior, si la pendiente es de 0.5, significa que por cada hora adicional de sol, la temperatura aumenta en 0.5ºC.

##10.¿Qué implicaciones conlleva obtener un intercepto con valor ‘0’?
1)Matematicamente podria implicar que cuando todas las variables independientes son iguales a cero, el valor esperado de la variable dependiente también es cero.
2)Esto podria ser motivo de sesgo en el modelo si los datos no están adecuadamente representados o que el modelo no se ajusta a los datos y necesita de una revisión.
3)En algunos casos puede ser práctico en el sentido de que un intercepto 0 simplemente puede representar un resultado poco probable en relación con la realidad del modelo.

##11.¿Qué ponderación lleva a cabo el análisis de regresión lineal para calcular los valores de los parámetros que configuran la recta de regresión?
El método comúnmente usado para calcular los valores de los parámetros que configuran la recta de regresión es el método de mínimos cuadrados, que tiene como objetivos disminuir las diferencias entre los valores observados de la variable y los valores predichos por el modelo.

##12.¿Cuál sería el error asociado a mi modelo en la estimación del número de cuentas para un yacimiento que se encuentra a 1.1 km de la mina?
Haciendo uso de la ecuación, le ponemos un valor a cada una de las entidades de la ecuacion, teniendo que la regresion lineal es Y=b0 + b1X + E (siendo E el error),despejamos la E y ponemos nuestro modelo en práctica. 
```{r echo=TRUE}

dist_cuentas <- data.frame(
  distancia = c(1.1, 150, 95.3, 4.4, 47.5, 7.6, 35.7, 67.8, 50.9, 84.1),
  num_cuentas = c(110, 5, 2, 92, 45, 95, 30, 3, 9, 11)
)
#Ajustar el modelo
modelo <- lm(num_cuentas ~ distancia, data = dist_cuentas)

# Predecir el número de cuentas para una distancia de 1.1 km
distancia_nueva <- 1.1
prediccion1 <- predict(modelo, newdata = data.frame(distancia = distancia_nueva))

# Encontrar el valor observado para esa distancia en tus datos
valor_observado <- dist_cuentas$num_cuentas[which(dist_cuentas$distancia == 1.1)]

# Calcular el error
error <- valor_observado - prediccion1

cat("El error es:", error, "\n")


```
##13.¿Cómo calcularías los residuos del modelo dado los siguientes datos?
```{r echo=TRUE}
calc_residuos<- data.frame(
  cuentas = c(6,98,40,94,31,5,8,10),
  prediction = c(-6.682842,85.520196,28.938591,84.216973,53.69983,19.924631,28.504183,-2.121561)
)

residuos <- calc_residuos$cuentas -  prediction

residuos
```
##14.Con los datos residuales, verifica si se cumple (o no) el supuesto de normalidad.
```{r echo=TRUE}

residuos <- residuals(modelo)

qqnorm(residuos)
qqline(residuos)

shapiro.test(residuos)
```
En este caso sí que cumple el supuesto de normalidad.

##15.¿Que 2 de conjuntos (de datos) se han de emplear en la modelización lineal? ¿Cómo llevarías a cabo la preparación de estos?
En primer lugar los datos de las variables que van a formar parte del modelo, pero en cuetión de entrenamiento para ajustarlo. Para prepararlos, escogeria una serie de muestras (de lo que sea) que sean representativas de los datos, diferenicar las variables (independeintes y dependientes), corregir los valores faltantes o que den error además de transformar esas variables si fuera necesario, y, por último, hacer una división de esos datos en unos subconjuntos a los que se les aplicará el modelo a modo de prueba.

En segundo lugar mencionaría los conjuntos de datos de prueba, los usados para evaluar el rendimiento del modelo en datos que no se les había aplicad en el entrenamiento. Esto implica: aplicar el mismo proceso de tratamiento de datos que en el entrenamiento (si fuera necesario), asegurarse de que todas las variables esten en el mismo formato en el que se ha entrenado al modelo, verificar que no haya errores en los valores o NA y asegurarque la distribucion de las variables sea similar al del conjunto de datos del entrenamiento.

##16.Evalúa la capacidad predictiva del modelo implementando una validación cruzada simple.
```{r echo=TRUE}
data <- data.frame(
  distancia = c(1.1, 100.2, 90.3, 5.4, 57.5, 6.6, 34.7, 65.8, 57.8, 86.1),
  num_cuentas = c(110, 2, 6, 98, 40, 94, 31, 5, 8, 10)
)

modelo <- lm(num_cuentas ~ distancia, data = data)

prediccionesmodelo <- predict(modelo, data)

plot(data$num_cuentas, prediccionesmodelo,
     xlab = "Valores Observados", ylab = "Valores Predichos",
     main = "Valores Observados vs. Valores Predichos")
abline(0, 1, col = "pink") 

correlacion <- cor(data$num_cuentas, prediccionesmodelo)
text(100, 100, paste("Correlación:", round(correlacion, 2)))




```

##17.Si mis coeficientes de regresión se han calculado con un intervalo de confianza del 95% ¿cuál será la probabilidad de que la correlación lineal entre los coeficientes de regresión y la variable de respuesta o explicada se deba al azar? ¿Y si tengo un nivel de significación (Alpha) de 0.01, con que Intervalo de Confianza he obtenido mis coeficientes de regresión?
La probabilidad de que la correlación lineal entre los coeficientes de regresión y la variable de respuesta se deba al azar es del 5%.

Con un nivel de significación Alpha el intervalo de confianza obtenido es de un 99%.

##18.Si las estimaciones arrojadas por mi modelo lineal resultan menos precisas (mayor error) en un determinado rango de valores con respecto a otro, decimos ¿qué hay indicios de homocedasticidad o heterocedasticidad?
Existirian indicios de heterocedasticidad.

##19.¿Qué medida de precisión estadística nos indica el % de variabilidad explicada de la variable dependiente por nuestro modelo lineal?
 Es el llamado coeficiente de determinación. 

##20.Explica la diferencia entre una observación atípica y una observación que produzca lo que se conoce en estadística como “apalancamiento” del modelo
Las observaciones atípicas se destacan por tener valores inusuales en la variable de respuesta, las observaciones de apalancamiento por tener valores inusuales en las variables predictoras. Ambos fenomenos afectan al modelo y deben ser tratados para obtener resultados validos y precisos. 